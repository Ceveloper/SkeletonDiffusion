pretrained_GM_folder: ${eval:"'./models/final_checkpoints/H36M/hmp/autoencoder/January19_19-24-04_ID1137310' if ${eval:"'${_load_saved_aoutoenc}'.split('-')[1] == 'h36m'"}   else './models/final_checkpoints/AMASS/hmp/autoencoder/May11_10-35-09_ID1185354'"} 
pretrained_autoencoder_path: '${model.pretrained_GM_folder}/checkpoints/checkpoint_final.pt' 

lr: 1.e-3 
diffusion_objective: pred_x0
weight_decay: 0.


if_use_ema: True
step_start_ema: 100 
ema_power: ${eval:'2/3'} 
ema_update_every: 10
ema_min_value: 0.0
use_lr_scheduler: True
lr_scheduler_kwargs: 
  lr_scheduler_type: ExponentialLRSchedulerWarmup 
  warmup_duration: 200
  update_every: 2
  min_lr: 1.e-4
  gamma_decay: 0.98

diffusion_conditioning: True
num_epochs: 600
num_workers: 4
batch_size: 64
batch_size_eval: 256 
if_run_validation: False
eval_frequency: 25  # in epochs
train_pick_best_sample_among_k: 50
similarity_space: input_space # input_space, latent_space or metric_space

diffusion_activation: identity
num_prob_samples: 50
diffusion_timesteps: 10

diffusion_type: IsotropicGaussianDiffusion
beta_schedule: cosine
diffusion_loss_type: l1
num_iter_perepoch: null
seed: 63485

diffusion_arch: 
    arch: Denoiser
    use_attention: True
    self_condition: False 
    norm_type: none
    depth: 4
    attn_dim_head: 32
    attn_heads: 8
    learn_influence: True